import gradio as gr
import argparse
import torchaudio
from tts import StepAudioTTS
from tokenizer import StepAudioTokenizer
from datetime import datetime
import os


# ä¿å­˜éŸ³é¢‘
def save_audio(audio_type, audio_data, sr):
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = os.path.join(args.tmp_dir, audio_type, f"{current_time}.wav")
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    torchaudio.save(save_path, audio_data, sr)
    return save_path


# æ™®é€šè¯­éŸ³åˆæˆ
def tts_common(text, speaker, emotion, language, speed):
    text = (
        (f"({emotion})" if emotion else "")
        + (f"({language})" if language else "")
        + (f"({speed})" if speed else "")
        + text
    )
    output_audio, sr = tts_engine(text, speaker)
    audio_type = "common"
    common_path = save_audio(audio_type, output_audio, sr)
    return common_path


# RAP / å“¼å”±æ¨¡å¼
def tts_music(text_input_rap, speaker, mode_input):
    text_input_rap = f"({mode_input})" + text_input_rap
    output_audio, sr = tts_engine(text_input_rap, speaker)
    audio_type = "music"
    music_path = save_audio(audio_type, output_audio, sr)
    return music_path


# è¯­éŸ³å…‹éš†
def tts_clone(text, wav_file, speaker_prompt, emotion, language, speed):
    clone_speaker = {
        "wav_path": wav_file,
        "speaker": "custom_voice",
        "prompt_text": speaker_prompt,
    }
    clone_text = (
        (f"({emotion})" if emotion else "")
        + (f"({language})" if language else "")
        + (f"({speed})" if speed else "")
        + text
    )
    output_audio, sr = tts_engine(clone_text, "", clone_speaker)
    audio_type = "clone"
    clone_path = save_audio(audio_type, output_audio, sr)
    return clone_path


def launch_demo(args):
    # é€‰é¡¹åˆ—è¡¨
    emotion_options = ["é«˜å…´1", "é«˜å…´2", "ç”Ÿæ°”1", "ç”Ÿæ°”2", "æ‚²ä¼¤1", "æ’’å¨‡1"]
    language_options = ["ä¸­æ–‡", "è‹±æ–‡", "éŸ©è¯­", "æ—¥è¯­", "å››å·è¯", "ç²¤è¯­", "å¹¿ä¸œè¯"]
    speed_options = ["æ…¢é€Ÿ1", "æ…¢é€Ÿ2", "å¿«é€Ÿ1", "å¿«é€Ÿ2"]
    speaker_options = ["Tingting"]
    # Gradio ç•Œé¢
    with gr.Blocks() as demo:
        gr.Markdown("## ğŸ™ï¸ Step-Audio-TTS-3B Demo")

        # æ™®é€šè¯­éŸ³åˆæˆ
        with gr.Tab("Common TTS (æ™®é€šè¯­éŸ³åˆæˆ)"):
            text_input = gr.Textbox(
                label="Input Text (è¾“å…¥æ–‡æœ¬)",
            )
            speaker_input = gr.Dropdown(
                speaker_options,
                label="Speaker Selection (éŸ³è‰²é€‰æ‹©)",
            )
            emotion_input = gr.Dropdown(
                emotion_options,
                label="Emotion Style (æƒ…æ„Ÿé£æ ¼)",
                allow_custom_value=True,
                interactive=True,
            )
            language_input = gr.Dropdown(
                language_options,
                label="Language/Dialect (è¯­è¨€/æ–¹è¨€)",
                allow_custom_value=True,
                interactive=True,
            )
            speed_input = gr.Dropdown(
                speed_options,
                label="Speech Rate (è¯­é€Ÿè°ƒèŠ‚)",
                allow_custom_value=True,
                interactive=True,
            )
            submit_btn = gr.Button("ğŸ”Š Generate Speech (ç”Ÿæˆè¯­éŸ³)")
            output_audio = gr.Audio(
                label="Output Audio (åˆæˆè¯­éŸ³)",
                interactive=False,
            )

            submit_btn.click(
                tts_common,
                inputs=[
                    text_input,
                    speaker_input,
                    emotion_input,
                    language_input,
                    speed_input,
                ],
                outputs=output_audio,
            )

        # RAP / å“¼å”±æ¨¡å¼
        with gr.Tab("RAP/Humming Mode (RAP/å“¼å”±æ¨¡å¼)"):
            text_input_rap = gr.Textbox(
                label="Lyrics Input (æ­Œè¯è¾“å…¥)",
            )
            speaker_input = gr.Dropdown(
                speaker_options,
                label="Speaker Selection (éŸ³è‰²é€‰æ‹©)",
            )
            mode_input = gr.Radio(
                ["RAP", "Humming (å“¼å”±)"],
                value="RAP",
                label="Generation Mode (ç”Ÿæˆæ¨¡å¼)",
            )
            submit_btn_rap = gr.Button("ğŸ¤ Generate Performance (ç”Ÿæˆæ¼”ç»)")
            output_audio_rap = gr.Audio(
                label="Performance Audio (æ¼”ç»éŸ³é¢‘)", interactive=False
            )
            submit_btn_rap.click(
                tts_music,
                inputs=[text_input_rap, speaker_input, mode_input],
                outputs=output_audio_rap,
            )

        with gr.Tab("Voice Clone (è¯­éŸ³å…‹éš†)"):
            text_input_clone = gr.Textbox(
                label="Target Text (ç›®æ ‡æ–‡æœ¬)",
                placeholder="Text to be synthesized with cloned voice (å¾…å…‹éš†è¯­éŸ³åˆæˆçš„æ–‡æœ¬)",
            )
            audio_input = gr.File(
                label="Reference Audio Upload (å‚è€ƒéŸ³é¢‘ä¸Šä¼ )",
            )
            speaker_prompt = gr.Textbox(
                label="Exact text from reference audio (è¾“å…¥å‚è€ƒéŸ³é¢‘çš„å‡†ç¡®æ–‡æœ¬)",
            )
            emotion_input = gr.Dropdown(
                emotion_options,
                label="Emotion Style (æƒ…æ„Ÿé£æ ¼)",
                allow_custom_value=True,
                interactive=True,
            )
            language_input = gr.Dropdown(
                language_options,
                label="Language/Dialect (è¯­è¨€/æ–¹è¨€)",
                allow_custom_value=True,
                interactive=True,
            )
            speed_input = gr.Dropdown(
                speed_options,
                label="Speech Rate (è¯­é€Ÿè°ƒèŠ‚)",
                allow_custom_value=True,
                interactive=True,
            )
            submit_btn_clone = gr.Button("ğŸ—£ï¸ Synthesize Cloned Speech (åˆæˆå…‹éš†è¯­éŸ³)")
            output_audio_clone = gr.Audio(
                label="Cloned Speech Output (å…‹éš†è¯­éŸ³è¾“å‡º)",
                interactive=False,
            )
            submit_btn_clone.click(
                tts_clone,
                inputs=[
                    text_input_clone,
                    audio_input,
                    speaker_prompt,
                    emotion_input,
                    language_input,
                    speed_input,
                ],
                outputs=output_audio_clone,
            )

    # å¯åŠ¨ Gradio demo
    demo.queue().launch(server_name=args.server_name, server_port=args.server_port)


if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser()
    parser.add_argument("--model-path", type=str, required=True, help="Model path.")
    parser.add_argument(
        "--server-name", type=str, default="0.0.0.0", help="Demo server name."
    )
    parser.add_argument(
        "--server-port", type=int, default=7860, help="Demo server port."
    )
    parser.add_argument("--tmp_dir", type=str, default="/tmp/gradio", help="Save path.")

    args = parser.parse_args()
    # ä½¿ç”¨è§£æåçš„å‘½ä»¤è¡Œå‚æ•°è®¾ç½®æ¨¡å‹è·¯å¾„
    model_path = args.model_path
    encoder = StepAudioTokenizer(os.path.join(model_path, "Step-Audio-Tokenizer"))
    tts_engine = StepAudioTTS(os.path.join(model_path, "Step-Audio-TTS-3B"), encoder)
    launch_demo(args)
