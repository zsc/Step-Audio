# Step-Audio 核心概念文档

## 一、名词解释

### 1. 核心组件
- **Step-Audio**: 业界首个集语音理解与生成控制一体化的产品级开源实时语音对话系统
- **Step-Audio-Chat**: 130B参数的多模态对话模型，支持语音输入输出
- **Step-Audio-TTS-3B**: 3B参数的语音合成模型，支持指令控制和语音克隆
- **Step-Audio-Tokenizer**: 音频编码器，将音频转换为离散标记

### 2. 技术概念
- **双码本框架 (Dual-codebook)**: 
  - **Linguistic Tokenizer**: 语言级编码器，码率16.7Hz，码本大小1024
  - **Semantic Tokenizer**: 声学级编码器，码率25Hz，码本大小4096
  - 时序交错比例 2:3（2个语言token对应3个声学token）

- **Flow Matching**: 流匹配技术，用于语音解码器生成高质量音频
- **Neural Vocoder**: 神经声码器，将梅尔频谱转换为波形
- **RLHF**: 基于人类反馈的强化学习，用于提升响应质量

### 3. 功能标签
- **情感控制**: 高兴、生气、悲伤、撒娇等
- **方言支持**: 粤语、四川话等
- **音乐能力**: RAP、哼唱
- **语速控制**: 慢速、快速

## 二、动词（主要功能）

### 1. 语音理解
- **语音识别 (ASR)**: 将音频转换为文本
- **语义理解**: 理解语音内容的含义
- **情感识别**: 识别说话者的情感状态

### 2. 语音生成
- **文本转语音 (TTS)**: 将文本转换为自然语音
- **语音克隆**: 模仿特定说话人的音色
- **情感控制**: 生成带有特定情感的语音
- **韵律控制**: 控制语速、音调等韵律特征

### 3. 对话交互
- **多轮对话**: 支持上下文相关的多轮交互
- **实时响应**: 流式处理实现低延迟交互
- **多语言支持**: 中文、英文、日语等

## 三、引擎（核心模块）

### 1. 编码引擎 (StepAudioTokenizer)
- **位置**: `tokenizer.py`
- **功能**: 音频到token的转换
- **核心方法**:
  - `wav2token()`: 音频转token
  - `get_vq02_code()`: 获取语言级编码
  - `get_vq06_code()`: 获取声学级编码
  - `merge_vq0206_to_token_str()`: 合并双码本

### 2. 语言模型引擎 (Step-Audio-Chat LLM)
- **位置**: `stepaudio.py`中的`self.llm`
- **功能**: 理解和生成对话内容
- **核心方法**:
  - `generate()`: 生成响应
  - `apply_chat_template()`: 应用对话模板

### 3. 合成引擎 (StepAudioTTS)
- **位置**: `tts.py`
- **功能**: token到语音的转换
- **核心组件**:
  - 3B参数语言模型
  - CosyVoice声码器（常规版和音乐版）
  - Flow Matching解码器

### 4. 实时推理引擎
- **VAD (Voice Activity Detection)**: 语音活动检测
- **Streaming Audio Tokenizer**: 流式音频分词
- **Context Manager**: 上下文管理器

## 四、点火钥匙（启动入口）

### 1. 主要入口文件
- **`offline_inference.py`**: 离线推理入口
  - 端到端音频/文本输入输出
  - 示例代码展示基本用法

- **`tts_inference.py`**: TTS推理入口
  - 支持默认音色合成
  - 支持语音克隆

- **`app.py`**: Web界面入口
  - Gradio界面
  - 支持麦克风输入和文本输入
  - 实时对话展示

- **`tts_app.py`**: TTS Web界面入口
  - 专门的TTS演示界面

### 2. 调用链路
```
用户输入 → StepAudioTokenizer（编码）
        → Step-Audio-Chat（理解+生成）
        → StepAudioTTS（合成）
        → 音频输出
```

### 3. 初始化流程
```python
# 1. 加载模型
model = StepAudio(
    tokenizer_path="Step-Audio-Tokenizer",
    tts_path="Step-Audio-TTS-3B", 
    llm_path="Step-Audio-Chat"
)

# 2. 处理输入
messages = [{"role": "user", "content": "..."}]

# 3. 生成响应
text, audio, sr = model(messages, speaker_id)
```

## 五、数据流向

### 1. 音频输入流程
```
原始音频 → 预处理(16kHz采样) → 双码本编码
       → Linguistic tokens (vq02)
       → Semantic tokens (vq06)  
       → 交错合并 → "<audio_xxxxx>"格式
```

### 2. 文本生成流程
```
编码后的音频/文本 → LLM处理 → 生成token序列
                → 解码为文本 → 提取音频tokens
```

### 3. 语音合成流程
```
文本+音色信息 → TTS模型生成tokens
            → CosyVoice解码 → Flow Matching
            → 音频波形输出
```

## 六、关键配置

### 1. 模型参数
- Chat模型: 130B参数，需要265GB显存
- TTS模型: 3B参数，需要8GB显存
- Tokenizer: 1.5GB显存

### 2. 音频参数
- 输入采样率: 16kHz (ASR), 22.05kHz (TTS)
- 输出采样率: 22.05kHz
- Token率: 16.7Hz (linguistic), 25Hz (semantic)

### 3. 推理参数
- Temperature: 0.7
- Top-p: 0.9
- Max tokens: 2048/8192